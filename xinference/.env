# ===========================
# Xinference 配置
# ===========================

# 1. 镜像版本
# 根据自己的硬件选择需要的版本
IMAGE_TAG=v1.17.1-cpu

# 2. 宿主机对外端口
# vLLM 用了 7000，这里我们用 7001
PORT=7001

# 3. 宿主机模型根目录
# 我们把你的模型目录挂载进去，这样 Xinference 可以直接读取本地已有的模型
MODEL_DIR=~/llm_models/modelscope

# 4. Xinference 内部数据存储
# 用于存放 logs, 下载的 cached 模型等
XINFERENCE_HOME=./.xinference